{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XMM-LSS master catalogue\n",
    "\n",
    "This notebook presents the merge of the pristine catalogues from CFHT Megacam. This has to be conducted separately on XMM-LSS due to the large amount of memory required on this field.\n",
    "\n",
    "This notebook also ingests all the CANDELS-UDS data apart from the photometry that needs to be merged in other 2.x notebooks.\n",
    "\n",
    "Since this is where we ingest all the CANDELS fluxes apert from UKIDSS and IRAC we take the opportunity here to merge them in with SXDS Suprime fluxes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from herschelhelp_internal import git_version\n",
    "print(\"This notebook was run with herschelhelp_internal version: \\n{}\".format(git_version()))\n",
    "import datetime\n",
    "print(\"This notebook was executed on: \\n{}\".format(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc('figure', figsize=(10, 6))\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "from astropy import units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.table import Column, Table\n",
    "import numpy as np\n",
    "from pymoc import MOC\n",
    "\n",
    "from herschelhelp_internal.masterlist import merge_catalogues, nb_merge_dist_plot, specz_merge\n",
    "from herschelhelp_internal.utils import coords_to_hpidx, ebv, gen_help_id, inMoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TMP_DIR = os.environ.get('TMP_DIR', \"./data_tmp\")\n",
    "OUT_DIR = os.environ.get('OUT_DIR', \"./data\")\n",
    "SUFFIX = os.environ.get('SUFFIX', time.strftime(\"_%Y%m%d\"))\n",
    "\n",
    "try:\n",
    "    os.makedirs(OUT_DIR)\n",
    "except FileExistsError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I - Reading the prepared pristine catalogues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#candels = Table.read(\"{}/CANDELS.fits\".format(TMP_DIR))           # 1.1\n",
    "candels = Table.read(\"{}/CANDELS-UDS.fits\".format(TMP_DIR))           # 1.2\n",
    "cfht_wirds = Table.read(\"{}/CFHT-WIRDS.fits\".format(TMP_DIR))     # 1.3\n",
    "cfhtls_wide = Table.read(\"{}/CFHTLS-WIDE.fits\".format(TMP_DIR))   # 1.4a\n",
    "cfhtls_deep = Table.read(\"{}/CFHTLS-DEEP.fits\".format(TMP_DIR))   # 1.4b\n",
    "#We no longer use CFHTLenS as it is the same raw data set as CFHTLS-WIDE\n",
    "# cfhtlens = Table.read(\"{}/CFHTLENS.fits\".format(TMP_DIR))         # 1.5\n",
    "#decals = Table.read(\"{}/DECaLS.fits\".format(TMP_DIR))             # 1.6\n",
    "#servs = Table.read(\"{}/SERVS.fits\".format(TMP_DIR))               # 1.8\n",
    "#swire = Table.read(\"{}/SWIRE.fits\".format(TMP_DIR))               # 1.7\n",
    "#hsc_wide = Table.read(\"{}/HSC-WIDE.fits\".format(TMP_DIR))         # 1.9a\n",
    "#hsc_deep = Table.read(\"{}/HSC-DEEP.fits\".format(TMP_DIR))         # 1.9b\n",
    "#hsc_udeep = Table.read(\"{}/HSC-UDEEP.fits\".format(TMP_DIR))       # 1.9c\n",
    "#ps1 = Table.read(\"{}/PS1.fits\".format(TMP_DIR))                   # 1.10\n",
    "sxds = Table.read(\"{}/SXDS.fits\".format(TMP_DIR))                 # 1.11\n",
    "sparcs = Table.read(\"{}/SpARCS.fits\".format(TMP_DIR))             # 1.12\n",
    "#dxs = Table.read(\"{}/UKIDSS-DXS.fits\".format(TMP_DIR))            # 1.13\n",
    "#uds = Table.read(\"{}/UKIDSS-UDS.fits\".format(TMP_DIR))            # 1.14\n",
    "vipers = Table.read(\"{}/VIPERS.fits\".format(TMP_DIR))             # 1.15\n",
    "#vhs = Table.read(\"{}/VISTA-VHS.fits\".format(TMP_DIR))             # 1.16\n",
    "#video = Table.read(\"{}/VISTA-VIDEO.fits\".format(TMP_DIR))         # 1.17\n",
    "#viking = Table.read(\"{}/VISTA-VIKING.fits\".format(TMP_DIR))       # 1.18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II - Merging tables\n",
    "\n",
    "We first merge the optical catalogues and then add the infrared ones. We start with PanSTARRS because it coevrs the whole field.\n",
    "\n",
    "At every step, we look at the distribution of the distances to the nearest source in the merged catalogue to determine the best crossmatching radius."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start with CANDELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_catalogue = candels\n",
    "master_catalogue['candels_ra'].name = 'ra'\n",
    "master_catalogue['candels_dec'].name = 'dec'\n",
    "del candels\n",
    "unused_bands = [ 'candels-ukidss', 'candels-irac']\n",
    "for col in master_catalogue.colnames:\n",
    "    \n",
    "    for band in unused_bands:\n",
    "        if band in col:\n",
    "            master_catalogue.remove_column(col)\n",
    "            print(col, ' removed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add CFHTLS-DEEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_merge_dist_plot(\n",
    "    SkyCoord(master_catalogue['ra'], master_catalogue['dec']),\n",
    "    SkyCoord(cfhtls_deep['cfhtls-deep_ra'], cfhtls_deep['cfhtls-deep_dec'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Given the graph above, we use 0.8 arc-second radius\n",
    "master_catalogue = merge_catalogues(master_catalogue, \n",
    "                                    cfhtls_deep, \n",
    "                                    \"cfhtls-deep_ra\", \n",
    "                                    \"cfhtls-deep_dec\", \n",
    "                                    radius=0.8*u.arcsec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Add CFHTLS-WIDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_merge_dist_plot(\n",
    "    SkyCoord(master_catalogue['ra'], master_catalogue['dec']),\n",
    "    SkyCoord(cfhtls_wide['cfhtls-wide_ra'], cfhtls_wide['cfhtls-wide_dec'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Given the graph above, we use 0.8 arc-second radius\n",
    "master_catalogue = merge_catalogues(master_catalogue, \n",
    "                                    cfhtls_wide, \n",
    "                                    \"cfhtls-wide_ra\", \n",
    "                                    \"cfhtls-wide_dec\", \n",
    "                                    radius=0.8*u.arcsec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add SpARCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_merge_dist_plot(\n",
    "    SkyCoord(master_catalogue['ra'], master_catalogue['dec']),\n",
    "    SkyCoord(sparcs['sparcs_ra'], sparcs['sparcs_dec'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Given the graph above, we use 0.8 arc-second radius\n",
    "master_catalogue = merge_catalogues(master_catalogue, sparcs, \"sparcs_ra\", \"sparcs_dec\", radius=0.8*u.arcsec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Add CFHT-WIRDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_merge_dist_plot(\n",
    "    SkyCoord(master_catalogue['ra'], master_catalogue['dec']),\n",
    "    SkyCoord(cfht_wirds['wirds_ra'], cfht_wirds['wirds_dec'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Given the graph above, we use 0.8 arc-second radius\n",
    "master_catalogue = merge_catalogues(master_catalogue, \n",
    "                                    cfht_wirds, \n",
    "                                    \"wirds_ra\", \n",
    "                                    \"wirds_dec\", \n",
    "                                    radius=0.8*u.arcsec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add VIPERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_merge_dist_plot(\n",
    "    SkyCoord(master_catalogue['ra'], master_catalogue['dec']),\n",
    "    SkyCoord(vipers['vipers_ra'], vipers['vipers_dec'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Given the graph above, we use 0.8 arc-second radius\n",
    "master_catalogue = merge_catalogues(master_catalogue, \n",
    "                                    vipers, \n",
    "                                    \"vipers_ra\", \n",
    "                                    \"vipers_dec\", \n",
    "                                    radius=0.8*u.arcsec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add SXDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_merge_dist_plot(\n",
    "    SkyCoord(master_catalogue['ra'], master_catalogue['dec']),\n",
    "    SkyCoord(sxds['sxds_ra'], sxds['sxds_dec'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Given the graph above, we use 0.8 arc-second radius\n",
    "master_catalogue = merge_catalogues(master_catalogue, \n",
    "                                    sxds, \n",
    "                                    \"sxds_ra\", \n",
    "                                    \"sxds_dec\", \n",
    "                                    radius=0.8*u.arcsec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning\n",
    "\n",
    "When we merge the catalogues, astropy masks the non-existent values (e.g. when a row comes only from a catalogue and has no counterparts in the other, the columns from the latest are masked for that row). We indicate to use NaN for masked values for floats columns, False for flag columns and -1 for ID columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in master_catalogue.colnames:\n",
    "    if \"m_\" in col or \"merr_\" in col or \"f_\" in col or \"ferr_\" in col or \"stellarity\" in col:\n",
    "        master_catalogue[col] = master_catalogue[col].astype(float)\n",
    "        master_catalogue[col].fill_value = np.nan\n",
    "    elif \"flag\" in col:\n",
    "        master_catalogue[col].fill_value = 0\n",
    "    elif \"id\" in col:\n",
    "        master_catalogue[col].fill_value = -1\n",
    "        \n",
    "master_catalogue = master_catalogue.filled()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Since this is not the final merged catalogue. We rename column names to make them unique\n",
    "master_catalogue['ra'].name = 'cfht_ra'\n",
    "master_catalogue['dec'].name = 'cfht_dec'\n",
    "master_catalogue['flag_merged'].name = 'cfht_flag_merged'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_catalogue[:10].show_in_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "master_catalogue.add_column(Column(data=(np.char.array(master_catalogue['cfhtls-wide_id'].astype(str)) \n",
    "                                    +  np.char.array(master_catalogue['cfhtls-deep_id'].astype(str) )\n",
    "                                         +  np.char.array(master_catalogue['candels_id'].astype(str) )\n",
    "                                    +  np.char.array(master_catalogue['sparcs_intid'].astype(str)) \n",
    "                                        +  np.char.array(master_catalogue['wirds_id'].astype(str)) \n",
    "                                        +  np.char.array(master_catalogue['vipers_id'].astype(str)) ), \n",
    "                              name=\"cfht_intid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_names = []\n",
    "for col in master_catalogue.colnames:\n",
    "    if '_id' in col:\n",
    "        id_names += [col]\n",
    "    if '_intid' in col:\n",
    "        id_names += [col]\n",
    "        \n",
    "print(id_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VII - Choosing between multiple values for the same filter\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Â VII.a CFHT Megacam fluxes: CFHTLS-DEEP, CFHTLS-WIDE SpARCS, CANDELS, CFHT-WIRDS and VIPERS\n",
    "\n",
    "According to Mattia CFHTLenS is built on the same data as CFHTLS-WIDE and should not be included. I have therefore excluded it from the merge above.\n",
    "\n",
    "CFHTLS-DEEP is prefferred to CFHTLS-WIDE which is prefferred to SpARCS... CANDELS... WIRDS... VIPERS\n",
    "\n",
    "| Survey (in HELP use order)            | Bands                 | notes |\n",
    "|:-------------|:------------------|-------------------|\n",
    "| CFHTLS-DEEP | u, g, r, i, z, y ||\n",
    "| CFHTLS-WIDE | u, g, r, i, z    ||\n",
    "| SpARCS      | u, g, r, z, y    ||\n",
    "| CANDELS     | u                | Total fluxes only |\n",
    "| CFHT-WIRDS     | u, g, r, i, z  (+ WIRCAM J, H, Ks)            ||\n",
    "| VIPERS     | u, g, r, i, z, y  (+ WIRCAM Ks)            | Total fluxes only |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "megacam_origin = Table()\n",
    "megacam_origin.add_column(master_catalogue['cfht_intid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "megacam_stats = Table()\n",
    "megacam_stats.add_column(Column(data=['u','g','r','i','z','y'], name=\"Band\"))\n",
    "for col in [\"CFHTLS-DEEP\", \"CFHTLS-WIDE\", \"SpARCS\", \"CANDELS\", \"CFHT-WIRDS\", \"VIPERS\"]:\n",
    "    megacam_stats.add_column(Column(data=np.full(6, 0), name=\"{}\".format(col)))\n",
    "    megacam_stats.add_column(Column(data=np.full(6, 0), name=\"use {}\".format(col)))\n",
    "    megacam_stats.add_column(Column(data=np.full(6, 0), name=\"{} ap\".format(col)))\n",
    "    megacam_stats.add_column(Column(data=np.full(6, 0), name=\"use {} ap\".format(col)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "megacam_bands = ['u','g','r','i','z','y'] # Lowercase naming convention (k is Ks)\n",
    "for band in megacam_bands:\n",
    "\n",
    "    # Megacam total flux \n",
    "    has_cfhtls_deep = ~np.isnan(master_catalogue['f_cfhtls-deep_' + band])\n",
    "    if band == 'y':\n",
    "        has_cfhtls_wide = np.full(len(master_catalogue), False, dtype=bool)\n",
    "    else:\n",
    "        has_cfhtls_wide = ~np.isnan(master_catalogue['f_cfhtls-wide_' + band])\n",
    "        \n",
    "    if band == 'i':\n",
    "        has_sparcs = np.full(len(master_catalogue), False, dtype=bool)\n",
    "    else:\n",
    "        has_sparcs = ~np.isnan(master_catalogue['f_sparcs_' + band])\n",
    "        \n",
    "    if band == 'u':\n",
    "        has_candels = ~np.isnan(master_catalogue['f_candels-megacam_' + band])\n",
    "    else:\n",
    "        has_candels = np.full(len(master_catalogue), False, dtype=bool)\n",
    "        \n",
    "    if band == 'y':\n",
    "        has_wirds = np.full(len(master_catalogue), False, dtype=bool)\n",
    "    else:\n",
    "        has_wirds = ~np.isnan(master_catalogue['f_wirds_' + band])\n",
    "        \n",
    "    has_vipers  = ~np.isnan(master_catalogue['f_vipers_' + band])\n",
    "    \n",
    "\n",
    "    use_cfhtls_deep = has_cfhtls_deep \n",
    "    use_cfhtls_wide = has_cfhtls_wide & ~has_cfhtls_deep\n",
    "    use_sparcs = has_sparcs & ~has_cfhtls_wide & ~has_cfhtls_deep\n",
    "    use_candels = has_candels & ~has_sparcs & ~has_cfhtls_wide & ~has_cfhtls_deep\n",
    "    use_wirds = has_wirds & ~has_candels & ~has_sparcs & ~has_cfhtls_wide & ~has_cfhtls_deep\n",
    "    use_vipers = has_vipers & ~has_wirds & ~has_candels & ~has_sparcs & ~has_cfhtls_wide & ~has_cfhtls_deep\n",
    "\n",
    "    f_megacam = np.full(len(master_catalogue), np.nan)\n",
    "    f_megacam[use_cfhtls_deep] = master_catalogue['f_cfhtls-deep_' + band][use_cfhtls_deep]\n",
    "    if not (band == 'y'):\n",
    "        f_megacam[use_cfhtls_wide] = master_catalogue['f_cfhtls-wide_' + band][use_cfhtls_wide]\n",
    "    if not (band == 'i'):\n",
    "        f_megacam[use_sparcs] = master_catalogue['f_sparcs_' + band][use_sparcs]\n",
    "    if band == 'u':\n",
    "        f_megacam[use_candels] = master_catalogue['f_candels-megacam_' + band][use_candels] \n",
    "    if not (band == 'y'):\n",
    "        f_megacam[use_wirds] = master_catalogue['f_wirds_' + band][use_wirds]\n",
    "    f_megacam[use_vipers] = master_catalogue['f_vipers_' + band][use_vipers]    \n",
    "\n",
    "    ferr_megacam = np.full(len(master_catalogue), np.nan)\n",
    "    ferr_megacam[use_cfhtls_deep] = master_catalogue['ferr_cfhtls-deep_' + band][use_cfhtls_deep]\n",
    "    if not (band == 'y'):\n",
    "        ferr_megacam[use_cfhtls_wide] = master_catalogue['ferr_cfhtls-wide_' + band][use_cfhtls_wide]\n",
    "    if not (band == 'i'):\n",
    "        ferr_megacam[use_sparcs] = master_catalogue['ferr_sparcs_' + band][use_sparcs]\n",
    "    if band == 'u':\n",
    "        ferr_megacam[use_candels] = master_catalogue['ferr_candels-megacam_' + band][use_candels]\n",
    "    if not (band == 'y'):\n",
    "        ferr_megacam[use_wirds] = master_catalogue['ferr_wirds_' + band][use_wirds]\n",
    "    ferr_megacam[use_vipers] = master_catalogue['ferr_vipers_' + band][use_vipers] \n",
    "    \n",
    "    m_megacam = np.full(len(master_catalogue), np.nan)\n",
    "    m_megacam[use_cfhtls_deep] = master_catalogue['m_cfhtls-deep_' + band][use_cfhtls_deep]\n",
    "    if not (band == 'y'):\n",
    "        m_megacam[use_cfhtls_wide] = master_catalogue['m_cfhtls-wide_' + band][use_cfhtls_wide]\n",
    "    if not (band == 'i'):\n",
    "        m_megacam[use_sparcs] = master_catalogue['m_sparcs_' + band][use_sparcs]\n",
    "    if band == 'u':\n",
    "        m_megacam[use_candels] = master_catalogue['m_candels-megacam_' + band][use_candels]\n",
    "    if not (band == 'y'):\n",
    "        m_megacam[use_wirds] = master_catalogue['m_wirds_' + band][use_wirds]\n",
    "    m_megacam[use_vipers] = master_catalogue['m_vipers_' + band][use_vipers] \n",
    "\n",
    "    merr_megacam = np.full(len(master_catalogue), np.nan)\n",
    "    merr_megacam[use_cfhtls_deep] = master_catalogue['merr_cfhtls-deep_' + band][use_cfhtls_deep]\n",
    "    if not (band == 'y'):\n",
    "        merr_megacam[use_cfhtls_wide] = master_catalogue['merr_cfhtls-wide_' + band][use_cfhtls_wide]\n",
    "    if not (band == 'i'):\n",
    "        merr_megacam[use_sparcs] = master_catalogue['merr_sparcs_' + band][use_sparcs]\n",
    "    if band == 'u':\n",
    "        merr_megacam[use_candels] = master_catalogue['merr_candels-megacam_' + band][use_candels]\n",
    "    if not (band == 'y'):\n",
    "        merr_megacam[use_wirds] = master_catalogue['merr_wirds_' + band][use_wirds]\n",
    "    merr_megacam[use_vipers] = master_catalogue['merr_vipers_' + band][use_vipers] \n",
    "\n",
    "    flag_megacam = np.full(len(master_catalogue), False, dtype=bool)\n",
    "    flag_megacam[use_cfhtls_deep] = master_catalogue['flag_cfhtls-deep_' + band][use_cfhtls_deep]\n",
    "    if not (band == 'y'):\n",
    "        flag_megacam[use_cfhtls_wide] = master_catalogue['flag_cfhtls-wide_' + band][use_cfhtls_wide]\n",
    "    if not (band == 'i'):\n",
    "        flag_megacam[use_sparcs] = master_catalogue['flag_sparcs_' + band][use_sparcs]\n",
    "    if band == 'u':\n",
    "        flag_megacam[use_candels] = master_catalogue['flag_candels-megacam_' + band][use_candels]\n",
    "    if not (band == 'y'):\n",
    "        flag_megacam[use_wirds] = master_catalogue['flag_wirds_' + band][use_wirds]\n",
    "    flag_megacam[use_vipers] = master_catalogue['flag_vipers_' + band][use_vipers] \n",
    "\n",
    "    master_catalogue.add_column(Column(data=f_megacam, name=\"f_megacam_\" + band))\n",
    "    master_catalogue.add_column(Column(data=ferr_megacam, name=\"ferr_megacam_\" + band))\n",
    "    master_catalogue.add_column(Column(data=m_megacam, name=\"m_megacam_\" + band))\n",
    "    master_catalogue.add_column(Column(data=merr_megacam, name=\"merr_megacam_\" + band))\n",
    "    master_catalogue.add_column(Column(data=flag_megacam, name=\"flag_megacam_\" + band))\n",
    "\n",
    "    \n",
    "    old_columns = []\n",
    "    column_types = ['f', 'ferr', 'm', 'merr', 'flag'] \n",
    "    for col_t in column_types:\n",
    "        old_columns += ['{}_cfhtls-deep_{}'.format(col_t, band)]\n",
    "        if not (band == 'y'):\n",
    "            old_columns += ['{}_cfhtls-wide_{}'.format(col_t, band)]\n",
    "        if not (band == 'i'):\n",
    "            old_columns += ['{}_sparcs_{}'.format(col_t, band)]    \n",
    "        if band == 'u':\n",
    "            old_columns += ['{}_candels-megacam_{}'.format(col_t, band)] \n",
    "        if not (band == 'y'):\n",
    "            old_columns += ['{}_wirds_{}'.format(col_t, band)] \n",
    "        old_columns += ['{}_vipers_{}'.format(col_t, band)]     \n",
    "        \n",
    "    master_catalogue.remove_columns(old_columns)\n",
    "\n",
    "    origin = np.full(len(master_catalogue), '     ', dtype='<U5')\n",
    "    origin[use_cfhtls_deep] = \"CFHTLS-DEEP\"\n",
    "    origin[use_cfhtls_wide] = \"CFHTLS-WIDE\"\n",
    "    origin[use_sparcs] = \"SpARCS\"\n",
    "    origin[use_candels] = \"CANDELS\"\n",
    "    origin[use_wirds] = \"WIRDS\"\n",
    "    origin[use_vipers] = \"VIPERS\"\n",
    "    \n",
    "    megacam_origin.add_column(Column(data=origin, name= 'f_megacam_' + band ))\n",
    "    \n",
    "    # Megacam aperture flux \n",
    "    has_ap_cfhtls_deep = ~np.isnan(master_catalogue['f_ap_cfhtls-deep_' + band])\n",
    "    if band == 'y':\n",
    "        has_ap_cfhtls_wide = np.full(len(master_catalogue), False, dtype=bool)\n",
    "    else:\n",
    "        has_ap_cfhtls_wide = ~np.isnan(master_catalogue['f_ap_cfhtls-wide_' + band])\n",
    "    if band == 'i':\n",
    "        has_ap_sparcs = np.full(len(master_catalogue), False, dtype=bool)\n",
    "    else:\n",
    "        has_ap_sparcs = ~np.isnan(master_catalogue['f_ap_sparcs_' + band])\n",
    "    if not (band == 'y'):\n",
    "        has_ap_wirds = ~np.isnan(master_catalogue['f_ap_wirds_' + band])\n",
    "    else:\n",
    "        has_ap_wirds = np.full(len(master_catalogue), False, dtype=bool)\n",
    "    \n",
    "\n",
    "    use_ap_cfhtls_deep = has_ap_cfhtls_deep \n",
    "    use_ap_cfhtls_wide = has_ap_cfhtls_wide & ~has_ap_cfhtls_deep\n",
    "    use_ap_sparcs = has_ap_sparcs & ~has_ap_cfhtls_wide & ~has_ap_cfhtls_deep\n",
    "    use_ap_wirds = has_ap_wirds & ~has_ap_sparcs & ~has_ap_cfhtls_wide & ~has_ap_cfhtls_deep\n",
    "\n",
    "    f_ap_megacam = np.full(len(master_catalogue), np.nan)\n",
    "    f_ap_megacam[use_ap_cfhtls_deep] = master_catalogue['f_ap_cfhtls-deep_' + band][use_ap_cfhtls_deep]\n",
    "    if not (band == 'y'):\n",
    "        f_ap_megacam[use_ap_cfhtls_wide] = master_catalogue['f_ap_cfhtls-wide_' + band][use_ap_cfhtls_wide]\n",
    "    if not (band == 'i'):\n",
    "        f_ap_megacam[use_ap_sparcs] = master_catalogue['f_ap_sparcs_' + band][use_ap_sparcs]\n",
    "    if not (band == 'y'):\n",
    "        f_ap_megacam[use_ap_wirds] = master_catalogue['f_ap_wirds_' + band][use_ap_wirds]\n",
    "        \n",
    "    ferr_ap_megacam = np.full(len(master_catalogue), np.nan)\n",
    "    ferr_ap_megacam[use_ap_cfhtls_deep] = master_catalogue['ferr_ap_cfhtls-deep_' + band][use_ap_cfhtls_deep]\n",
    "    if not (band == 'y'):\n",
    "        ferr_ap_megacam[use_ap_cfhtls_wide] = master_catalogue['ferr_ap_cfhtls-wide_' + band][use_ap_cfhtls_wide]\n",
    "    if not (band == 'i'):\n",
    "        ferr_ap_megacam[use_ap_sparcs] = master_catalogue['ferr_ap_sparcs_' + band][use_ap_sparcs]\n",
    "    if not (band == 'y'):\n",
    "        ferr_ap_megacam[use_ap_wirds] = master_catalogue['ferr_ap_wirds_' + band][use_ap_wirds]\n",
    "    \n",
    "    m_ap_megacam = np.full(len(master_catalogue), np.nan)\n",
    "    m_ap_megacam[use_ap_cfhtls_deep] = master_catalogue['m_ap_cfhtls-deep_' + band][use_ap_cfhtls_deep]\n",
    "    if not (band == 'y'):\n",
    "        m_ap_megacam[use_ap_cfhtls_wide] = master_catalogue['m_ap_cfhtls-wide_' + band][use_ap_cfhtls_wide]\n",
    "    if not (band == 'i'):\n",
    "        m_ap_megacam[use_ap_sparcs] = master_catalogue['m_ap_sparcs_' + band][use_ap_sparcs]\n",
    "    if not (band == 'y'):\n",
    "        m_ap_megacam[use_ap_wirds] = master_catalogue['m_ap_wirds_' + band][use_ap_wirds]\n",
    "\n",
    "    merr_ap_megacam = np.full(len(master_catalogue), np.nan)\n",
    "    merr_ap_megacam[use_ap_cfhtls_deep] = master_catalogue['merr_ap_cfhtls-deep_' + band][use_ap_cfhtls_deep]\n",
    "    if not (band == 'y'):\n",
    "        merr_ap_megacam[use_ap_cfhtls_wide] = master_catalogue['merr_ap_cfhtls-wide_' + band][use_ap_cfhtls_wide]\n",
    "    if not (band == 'i'):\n",
    "        merr_ap_megacam[use_ap_sparcs] = master_catalogue['merr_ap_sparcs_' + band][use_ap_sparcs]\n",
    "    if not (band == 'y'):\n",
    "        merr_ap_megacam[use_ap_wirds] = master_catalogue['merr_ap_wirds_' + band][use_ap_wirds]\n",
    "\n",
    "\n",
    "\n",
    "    master_catalogue.add_column(Column(data=f_ap_megacam, name=\"f_ap_megacam_\" + band))\n",
    "    master_catalogue.add_column(Column(data=ferr_ap_megacam, name=\"ferr_ap_megacam_\" + band))\n",
    "    master_catalogue.add_column(Column(data=m_ap_megacam, name=\"m_ap_megacam_\" + band))\n",
    "    master_catalogue.add_column(Column(data=merr_ap_megacam, name=\"merr_ap_megacam_\" + band))\n",
    "\n",
    "\n",
    "    \n",
    "    old_ap_columns = []\n",
    "    column_types = ['f', 'ferr', 'm', 'merr'] \n",
    "    for col_t in column_types:\n",
    "        old_ap_columns += ['{}_ap_cfhtls-deep_{}'.format(col_t, band)]\n",
    "        if not (band == 'y'):\n",
    "            old_ap_columns += ['{}_ap_cfhtls-wide_{}'.format(col_t, band)]\n",
    "        if not (band == 'i'):\n",
    "            old_ap_columns += ['{}_ap_sparcs_{}'.format(col_t, band)]    \n",
    "        if not (band == 'y'):\n",
    "            old_ap_columns += ['{}_ap_wirds_{}'.format(col_t, band)] \n",
    "    \n",
    "        \n",
    "    master_catalogue.remove_columns(old_ap_columns)\n",
    "\n",
    "    origin_ap = np.full(len(master_catalogue), '     ', dtype='<U5')\n",
    "    origin_ap[use_ap_cfhtls_deep] = \"CFHTLS-DEEP\"\n",
    "    origin_ap[use_ap_cfhtls_wide] = \"CFHTLS-WIDE\"\n",
    "    origin_ap[use_ap_sparcs] = \"SpARCS\"\n",
    "    origin_ap[use_ap_wirds] = \"CFHT-WIRDS\"\n",
    "    \n",
    "    megacam_origin.add_column(Column(data=origin_ap, name= 'f_ap_megacam_' + band ))\n",
    "    \n",
    "\n",
    "   \n",
    "    megacam_stats['CFHTLS-DEEP'][megacam_stats['Band'] == band] = np.sum(has_cfhtls_deep)\n",
    "    megacam_stats['CFHTLS-WIDE'][megacam_stats['Band'] == band] = np.sum(has_cfhtls_wide)\n",
    "    megacam_stats['SpARCS'][megacam_stats['Band'] == band] = np.sum(has_sparcs)\n",
    "    megacam_stats['CANDELS'][megacam_stats['Band'] == band] = np.sum(has_candels)\n",
    "    megacam_stats['CFHT-WIRDS'][megacam_stats['Band'] == band] = np.sum(has_wirds)\n",
    "    megacam_stats['VIPERS'][megacam_stats['Band'] == band] = np.sum(has_vipers)\n",
    "    megacam_stats['use CFHTLS-DEEP'][megacam_stats['Band'] == band] = np.sum(use_cfhtls_deep)\n",
    "    megacam_stats['use CFHTLS-WIDE'][megacam_stats['Band'] == band] = np.sum(use_cfhtls_wide)\n",
    "    megacam_stats['use SpARCS'][megacam_stats['Band'] == band] = np.sum(use_sparcs)\n",
    "    megacam_stats['use CANDELS'][megacam_stats['Band'] == band] = np.sum(use_candels)\n",
    "    megacam_stats['use CFHT-WIRDS'][megacam_stats['Band'] == band] = np.sum(use_wirds)\n",
    "    megacam_stats['use VIPERS'][megacam_stats['Band'] == band] = np.sum(use_vipers)\n",
    "    \n",
    "    megacam_stats['CFHTLS-DEEP ap'][megacam_stats['Band'] == band] = np.sum(has_ap_cfhtls_deep)\n",
    "    megacam_stats['CFHTLS-WIDE ap'][megacam_stats['Band'] == band] = np.sum(has_ap_cfhtls_wide)\n",
    "    megacam_stats['SpARCS ap'][megacam_stats['Band'] == band] = np.sum(has_ap_sparcs)\n",
    "    megacam_stats['CFHT-WIRDS ap'][megacam_stats['Band'] == band] = np.sum(has_ap_wirds)\n",
    "    megacam_stats['use CFHTLS-DEEP ap'][megacam_stats['Band'] == band] = np.sum(use_ap_cfhtls_deep)\n",
    "    megacam_stats['use CFHTLS-WIDE ap'][megacam_stats['Band'] == band] = np.sum(use_ap_cfhtls_wide)\n",
    "    megacam_stats['use SpARCS ap'][megacam_stats['Band'] == band] = np.sum(use_ap_sparcs)\n",
    "    megacam_stats['use CFHT-WIRDS ap'][megacam_stats['Band'] == band] = np.sum(use_ap_wirds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "megacam_stats.show_in_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "megacam_origin.write(\"{}/xmm-lss_megacam_fluxes_origins{}.fits\".format(OUT_DIR, SUFFIX), overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VII.b CFHT WIRCAM fluxes: CFHT-WIRDS and VIPERS\n",
    "\n",
    "We take WIRDS over VIPERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in master_catalogue.colnames:\n",
    "    if '_wirds_j' in col:\n",
    "        master_catalogue.rename_column(col, col.replace('_wirds_j', '_wircam_j'))\n",
    "    if '_wirds_h' in col:\n",
    "        master_catalogue.rename_column(col, col.replace('_wirds_h', '_wircam_h'))\n",
    "    if '_wirds_k' in col:\n",
    "        master_catalogue.rename_column(col, col.replace('_wirds_k', '_wircam_ks'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "has_wirds = ~np.isnan(master_catalogue['f_wircam_ks' ])\n",
    "has_vipers = ~np.isnan(master_catalogue['f_vipers_ks' ])\n",
    "\n",
    "use_wirds = has_wirds\n",
    "use_vipers = has_vipers & ~has_wirds\n",
    "\n",
    "master_catalogue['f_wircam_ks'][use_vipers] = master_catalogue['f_vipers_ks'][use_vipers]\n",
    "master_catalogue['ferr_wircam_ks'][use_vipers] = master_catalogue['ferr_vipers_ks'][use_vipers]\n",
    "master_catalogue['m_wircam_ks'][use_vipers] = master_catalogue['m_vipers_ks'][use_vipers]\n",
    "master_catalogue['merr_wircam_ks'][use_vipers] = master_catalogue['merr_vipers_ks'][use_vipers]\n",
    "master_catalogue['flag_wircam_ks'][use_vipers] = master_catalogue['flag_vipers_ks'][use_vipers]\n",
    "\n",
    "master_catalogue.remove_columns(['f_vipers_ks', 'ferr_vipers_ks', 'm_vipers_ks', 'merr_vipers_ks', 'flag_vipers_ks'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('There are {} objects with WIRDS Ks fluxes and {} with VIPERS Ks.'.format(np.sum(has_wirds), np.sum(has_vipers)))\n",
    "print('We use all {} Ks fluxes and take the remaining {} VIPERS Ks fluxes.'.format(np.sum(use_wirds), np.sum(use_vipers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wircam_origin = Table()\n",
    "wircam_origin.add_column(master_catalogue['cfht_intid'])\n",
    "origin = np.full(len(master_catalogue), '     ', dtype='<U5')\n",
    "origin[use_wirds] = \"CFHT-WIRDS\"\n",
    "origin[use_vipers] = \"VIPERS\"\n",
    "wircam_origin.add_column(Column(data=origin, name= 'f_wircam_ks'  ))\n",
    "wircam_origin.write(\"{}/xmm-lss_wircam_fluxes_origins{}.fits\".format(OUT_DIR, SUFFIX), overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VII.c Subaru SuprimeCam fluxes: SXDS and CANDELS-UDS\n",
    "\n",
    "We take SXDS over CANDELS so that there are not objects with total and ap mags from different source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "suprime_origin = Table()\n",
    "suprime_origin.add_column(master_catalogue['cfht_intid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "suprime_stats = Table()\n",
    "suprime_bands = ['b', 'v', 'rc', 'ip', 'zp']\n",
    "suprime_stats.add_column(Column(data=suprime_bands, name=\"Band\"))\n",
    "for col in [\"SXDS\", \"CANDELS-UDS\"]:\n",
    "    suprime_stats.add_column(Column(data=np.full(5, 0), name=\"{}\".format(col)))\n",
    "    suprime_stats.add_column(Column(data=np.full(5, 0), name=\"use {}\".format(col)))\n",
    "    suprime_stats.add_column(Column(data=np.full(5, 0), name=\"{} ap\".format(col)))\n",
    "    suprime_stats.add_column(Column(data=np.full(5, 0), name=\"use {} ap\".format(col)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "suprime_bands = ['b', 'v', 'rc', 'ip', 'zp']\n",
    "for band in suprime_bands:\n",
    "\n",
    "    # SuprimeCam total flux \n",
    "    has_candels = ~np.isnan(master_catalogue['f_suprime_' + band])\n",
    "    has_sxds = ~np.isnan(master_catalogue['f_sxds-suprime_' + band])\n",
    "\n",
    "     \n",
    "    use_sxds = has_sxds \n",
    "    use_candels = has_candels & ~has_sxds\n",
    "\n",
    "\n",
    "    f_suprime = np.full(len(master_catalogue), np.nan)\n",
    "    f_suprime[use_candels] = master_catalogue['f_suprime_' + band][use_candels]\n",
    "    f_suprime[use_sxds] = master_catalogue['f_sxds-suprime_' + band][use_sxds]\n",
    "\n",
    "    ferr_suprime = np.full(len(master_catalogue), np.nan)\n",
    "    ferr_suprime[use_candels] = master_catalogue['ferr_suprime_' + band][use_candels]\n",
    "    ferr_suprime[use_sxds] = master_catalogue['ferr_sxds-suprime_' + band][use_sxds]\n",
    "    \n",
    "    m_suprime = np.full(len(master_catalogue), np.nan)\n",
    "    m_suprime[use_candels] = master_catalogue['m_suprime_' + band][use_candels]\n",
    "    m_suprime[use_sxds] = master_catalogue['m_sxds-suprime_' + band][use_sxds]\n",
    "    \n",
    "    merr_suprime = np.full(len(master_catalogue), np.nan)\n",
    "    merr_suprime[use_candels] = master_catalogue['merr_suprime_' + band][use_candels]\n",
    "    merr_suprime[use_sxds] = master_catalogue['merr_sxds-suprime_' + band][use_sxds]\n",
    "    \n",
    "    flag_suprime = np.full(len(master_catalogue), False, dtype=bool)\n",
    "    flag_suprime[use_candels] = master_catalogue['flag_suprime_' + band][use_candels]\n",
    "    flag_suprime[use_sxds] = master_catalogue['flag_sxds-suprime_' + band][use_sxds]\n",
    "\n",
    "    master_catalogue[\"f_suprime_\" + band][use_sxds] = master_catalogue[\"f_sxds-suprime_\" + band][use_sxds]\n",
    "    master_catalogue[\"ferr_suprime_\" + band][use_sxds] = master_catalogue[\"ferr_sxds-suprime_\" + band][use_sxds]\n",
    "    master_catalogue[\"m_suprime_\" + band][use_sxds] = master_catalogue[\"m_sxds-suprime_\" + band][use_sxds]\n",
    "    master_catalogue[\"merr_suprime_\" + band][use_sxds] = master_catalogue[\"merr_sxds-suprime_\" + band][use_sxds]\n",
    "    master_catalogue[\"flag_suprime_\" + band][use_sxds] = master_catalogue[\"flag_sxds-suprime_\" + band][use_sxds]\n",
    "\n",
    "\n",
    "    old_sxds_columns =      ['f_sxds-suprime_' + band,\n",
    "                               'ferr_sxds-suprime_' + band,\n",
    "                               'm_sxds-suprime_' + band, \n",
    "                               'merr_sxds-suprime_' + band,\n",
    "                               'flag_sxds-suprime_' + band]\n",
    "    \n",
    "\n",
    "    master_catalogue.remove_columns(old_sxds_columns)\n",
    "\n",
    "    origin = np.full(len(master_catalogue), '     ', dtype='<U7')\n",
    "    origin[use_candels] = \"CANDELS\"\n",
    "    origin[use_sxds] = \"SXDS\"\n",
    "\n",
    "    \n",
    "    suprime_origin.add_column(Column(data=origin, name= 'f_suprime_' + band ))\n",
    "        \n",
    "\n",
    "   \n",
    "    suprime_stats['CANDELS-UDS'][suprime_stats['Band'] == band] = np.sum(has_candels)\n",
    "    suprime_stats['SXDS'][suprime_stats['Band'] == band] = np.sum(has_sxds)\n",
    "\n",
    "    suprime_stats['use CANDELS-UDS'][suprime_stats['Band'] == band] = np.sum(use_candels)\n",
    "    suprime_stats['use SXDS'][suprime_stats['Band'] == band] = np.sum(use_sxds)\n",
    "    \n",
    "    suprime_stats['CANDELS-UDS ap'][suprime_stats['Band'] == band] = 0\n",
    "    has_ap_sxds = np.sum( ~np.isnan(master_catalogue['f_ap_sxds-suprime_' + band]))\n",
    "    suprime_stats['SXDS ap'][suprime_stats['Band'] == band] = has_ap_sxds\n",
    "\n",
    "    suprime_stats['use CANDELS-UDS ap'][suprime_stats['Band'] == band] = 0\n",
    "    suprime_stats['use SXDS ap'][suprime_stats['Band'] == band] = has_ap_sxds\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Aperture fluxes all from SXDS\n",
    "for col in master_catalogue.colnames:\n",
    "    if '_ap_sxds-suprime_' in col:\n",
    "        master_catalogue.rename_column(col, col.replace('_ap_sxds-suprime_', '_ap_suprime_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suprime_stats.show_in_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "suprime_origin.write(\"{}/xmm-lss_suprime_fluxes_origins{}.fits\".format(OUT_DIR, SUFFIX), overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_catalogue[:10].show_in_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XI - Saving the catalogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "master_catalogue.write(\"{}/cfht_merged_catalogue_xmm-lss.fits\".format(TMP_DIR), overwrite=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (herschelhelp_internal)",
   "language": "python",
   "name": "helpint"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
