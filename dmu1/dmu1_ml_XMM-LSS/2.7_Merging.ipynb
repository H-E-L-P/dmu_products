{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XMM-LSS master catalogue\n",
    "\n",
    "This notebook presents the merge of the various pristine catalogues to produce the HELP master catalogue on XMM-LSS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from herschelhelp_internal import git_version\n",
    "print(\"This notebook was run with herschelhelp_internal version: \\n{}\".format(git_version()))\n",
    "import datetime\n",
    "print(\"This notebook was executed on: \\n{}\".format(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc('figure', figsize=(10, 6))\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "from astropy import units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.table import Column, Table, join\n",
    "import numpy as np\n",
    "from pymoc import MOC\n",
    "\n",
    "from herschelhelp_internal.masterlist import merge_catalogues, nb_merge_dist_plot, specz_merge\n",
    "from herschelhelp_internal.utils import coords_to_hpidx, ebv, gen_help_id, inMoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TMP_DIR = os.environ.get('TMP_DIR', \"./data_tmp\")\n",
    "OUT_DIR = os.environ.get('OUT_DIR', \"./data\")\n",
    "SUFFIX = os.environ.get('SUFFIX', time.strftime(\"_%Y%m%d\"))\n",
    "\n",
    "try:\n",
    "    os.makedirs(OUT_DIR)\n",
    "except FileExistsError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I - Reading the prepared pristine catalogues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SXDS now merged in with CANDELS in CFHT merge notebook\n",
    "#sxds = Table.read(\"{}/SXDS.fits\".format(TMP_DIR)\n",
    "#                 )[\"sxds_intid\", \n",
    "#                   \"sxds_ra\", \n",
    "#                   \"sxds_dec\",\n",
    "#                  # 'sxds_flag_merged'\n",
    "#                  ]                 # 1.11\n",
    "\n",
    "#WIRCAM:\n",
    "#cfht_wirds = Table.read(\"{}/CFHT-WIRDS.fits\".format(TMP_DIR)\n",
    "#                       )[\"wirds_intid\",\n",
    "#                         \"wirds_ra\",\n",
    "#                         \"wirds_dec\"]     # 1.3\n",
    "\n",
    "#Megacam:\n",
    "#candels = Table.read(\"{}/CANDELS.fits\".format(TMP_DIR)\n",
    "#                    )[\"candels_id\",\n",
    "#                      \"candels_ra\",\n",
    "#                      \"candels_dec\"]           # 1.1\n",
    "#cfhtls_wide = Table.read(\"{}/CFHTLS-WIDE.fits\".format(TMP_DIR)\n",
    "#                        )[\"cfhtls-wide_id\",\n",
    "#                          \"cfhtls-wide_ra\",\n",
    "#                          \"cfhtls-wide_dec\",\n",
    "#                          \"cfhtls-wide_stellarity\"]   # 1.4a\n",
    "#cfhtls_deep = Table.read(\"{}/CFHTLS-DEEP.fits\".format(TMP_DIR)\n",
    "#                        )[\"cfhtls-deep_id\",\n",
    "#                          \"cfhtls-deep_ra\",\n",
    "#                          \"cfhtls-deep_dec\",\n",
    "#                          \"cfhtls-deep_stellarity\"]   # 1.4b\n",
    "#We no longer use CFHTLenS as it is the same raw data set as CFHTLS-WIDE\n",
    "# cfhtlens = Table.read(\"{}/CFHTLENS.fits\".format(TMP_DIR))         # 1.5\n",
    "#sparcs = Table.read(\"{}/SpARCS.fits\".format(TMP_DIR)\n",
    "#                   )['sparcs_intid', \n",
    "#                     'sparcs_ra', \n",
    "#                     'sparcs_dec', \n",
    "#                     'sparcs_stellarity']             # 1.12\n",
    "#\n",
    "#vipers = Table.read(\"{}/VIPERS.fits\".format(TMP_DIR)\n",
    "#                   )[\"vipers_id\",\n",
    "#                     \"vipers_ra\",\n",
    "#                     \"vipers_dec\"]             # 1.15\n",
    "cfht = Table.read(\"{}/cfht_merged_catalogue_xmm-lss.fits\".format(TMP_DIR)\n",
    "                   )['cfht_intid', \n",
    "                     \"candels_id\",\n",
    "                     \"cfhtls-wide_id\",\n",
    "                     \"cfhtls-deep_id\",\n",
    "                     'sparcs_intid',\n",
    "                     'wirds_id',\n",
    "                     'vipers_id',\n",
    "                     'sxds_intid',\n",
    "                     'sxds_b_id',\n",
    "                     'sxds_v_id',\n",
    "                     'sxds_r_id',\n",
    "                     'sxds_i_id',\n",
    "                     'sxds_z_id',\n",
    "                     'cfht_ra', \n",
    "                     'cfht_dec']             # 1.12\n",
    "\n",
    "\n",
    "\n",
    "#DECam:\n",
    "#decals = Table.read(\"{}/DECaLS.fits\".format(TMP_DIR)\n",
    "#                   )[\"decals_id\",\n",
    "#                     \"decals_ra\",\n",
    "#                     \"decals_dec\"]             # 1.6\n",
    "decam = Table.read(\"{}/decam_merged_catalogue_xmm-lss.fits\".format(TMP_DIR)\n",
    "                   )[\"decam_intid\",\n",
    "                     \"decals_id\",\n",
    "                     \"des_id\",\n",
    "                     \"decam_ra\",\n",
    "                     \"decam_dec\"]             # 1.6\n",
    "\n",
    "#Spitzer IRAC:\n",
    "#servs = Table.read(\"{}/SERVS.fits\".format(TMP_DIR)\n",
    "#                  )[\"servs_intid\",\n",
    "#                    \"servs_ra\",\n",
    "#                    \"servs_dec\"]               # 1.8\n",
    "#swire = Table.read(\"{}/SWIRE.fits\".format(TMP_DIR)\n",
    "#                  )[\"swire_intid\",\n",
    "#                    \"swire_ra\",\n",
    "#                    \"swire_dec\"]               # 1.7\n",
    "irac = Table.read(\"{}/irac_merged_catalogue_xmm-lss.fits\".format(TMP_DIR)\n",
    "                  )[\"irac_intid\",\n",
    "                    \"servs_intid\",\n",
    "                    \"swire_intid\",\n",
    "                    \"irac_ra\",\n",
    "                    \"irac_dec\"]               # 1.7\n",
    "\n",
    "\n",
    "#Hyper Suprime Cam:\n",
    "#hsc_wide = Table.read(\"{}/HSC-WIDE.fits\".format(TMP_DIR)\n",
    "#                     )[\"hsc-wide_id\",\n",
    "#                       \"hsc-wide_ra\",\n",
    "#                       \"hsc-wide_dec\", \n",
    "#                       \"hsc-wide_stellarity\"]         # 1.9a\n",
    "#hsc_deep = Table.read(\"{}/HSC-DEEP.fits\".format(TMP_DIR)\n",
    "#                     )[\"hsc-deep_id\",\n",
    "#                       \"hsc-deep_ra\",\n",
    "#                       \"hsc-deep_dec\", \n",
    "#                       \"hsc-deep_stellarity\"]         # 1.9b\n",
    "#hsc_udeep = Table.read(\"{}/HSC-UDEEP.fits\".format(TMP_DIR)\n",
    "#                      )[\"hsc-udeep_id\",\n",
    "#                        \"hsc-udeep_ra\",\n",
    "#                        \"hsc-udeep_dec\", \n",
    "#                        \"hsc-udeep_stellarity\"]       # 1.9c\n",
    "hsc = Table.read(\"{}/hsc_merged_catalogue_xmm-lss.fits\".format(TMP_DIR)\n",
    "                      )[\"hsc_intid\",\n",
    "                        \"hsc_ra\",\n",
    "                        \"hsc_dec\", \n",
    "                        \"hsc-wide_id\",\n",
    "                        \"hsc-deep_id\",\n",
    "                        \"hsc-udeep_id\"]       # 1.9c\n",
    "\n",
    "\n",
    "#GPC1:\n",
    "ps1 = Table.read(\"{}/PS1.fits\".format(TMP_DIR)\n",
    "                )[\"ps1_id\",\n",
    "                  \"ps1_ra\",\n",
    "                  \"ps1_dec\"]                   # 1.10\n",
    "\n",
    "# UKIDSS WFCAM:\n",
    "#dxs = Table.read(\"{}/UKIDSS-DXS.fits\".format(TMP_DIR)\n",
    "#                )['dxs_id',\n",
    "#                  'dxs_ra',\n",
    "#                  'dxs_dec', \n",
    "#                  'dxs_stellarity']            # 1.13\n",
    "#uds = Table.read(\"{}/UKIDSS-UDS.fits\".format(TMP_DIR)\n",
    "#                )['uds_id',\n",
    "#                  'uds_ra',\n",
    "#                  'uds_dec',\n",
    "#                  'uds_stellarity']            # 1.14\n",
    "ukidss = Table.read(\"{}/ukidss_merged_catalogue_xmm-lss.fits\".format(TMP_DIR)\n",
    "                )['ukidss_intid',\n",
    "                  'dxs_id',\n",
    "                  'uds_id',\n",
    "                  'ukidss_ra',\n",
    "                  'ukidss_dec',\n",
    "                 # 'ukidss_stellarity'\n",
    "                 ]            # 1.14\n",
    "\n",
    "\n",
    "\n",
    "#VIRCAM:\n",
    "#vhs = Table.read(\"{}/VISTA-VHS.fits\".format(TMP_DIR)\n",
    "#                )[\"vhs_id\",\n",
    "#                  \"vhs_ra\",\n",
    "#                  \"vhs_dec\",\n",
    "#                  \"vhs_stellarity\"]             # 1.16\n",
    "#video = Table.read(\"{}/VISTA-VIDEO.fits\".format(TMP_DIR)\n",
    "#                  )['video_id',\n",
    "#                    'video_ra',\n",
    "#                    'video_dec',\n",
    "#                    'video_stellarity',\n",
    "#                    'video_flag_gaia']         # 1.17\n",
    "#viking = Table.read(\"{}/VISTA-VIKING.fits\".format(TMP_DIR)\n",
    "#                   )[\"viking_id\",\n",
    "#                     \"viking_ra\",\n",
    "#                     \"viking_dec\",\n",
    "#                     \"viking_stellarity\",\n",
    "#                     \"viking_flag_gaia\"]       # 1.18\n",
    "vircam = Table.read(\"{}/vista_merged_catalogue_xmm-lss.fits\".format(TMP_DIR)\n",
    "                   )[\"vircam_intid\",\n",
    "                     \"vhs_id\",\n",
    "                     'video_id',\n",
    "                     \"viking_id\",\n",
    "                     \"vircam_ra\",\n",
    "                     \"vircam_dec\",\n",
    "                     #\"vircam_stellarity\",\n",
    "                     #\"vircam_flag_gaia\"\n",
    "                    ] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II - Merging tables\n",
    "\n",
    "We first merge the optical catalogues and then add the infrared ones. We start with PanSTARRS because it coevrs the whole field.\n",
    "\n",
    "At every step, we look at the distribution of the distances to the nearest source in the merged catalogue to determine the best crossmatching radius."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add PanSTARRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "master_catalogue = ps1\n",
    "master_catalogue['ps1_ra'].name = 'ra'\n",
    "master_catalogue['ps1_dec'].name = 'dec'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CANDELS\n",
    "\n",
    "We now use CANDELS-UDS which must be individually merged with the merged catalogues since it has measurements from different instruments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#nb_merge_dist_plot(\n",
    "#    SkyCoord(master_catalogue['ra'], master_catalogue['dec']),\n",
    "#    SkyCoord(candels['candels_ra'], candels['candels_dec'])\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Given the graph above, we use 0.8 arc-second radius\n",
    "#master_catalogue = merge_catalogues(master_catalogue, candels, \"candels_ra\", \"candels_dec\", radius=0.8*u.arcsec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add CFHT\n",
    "\n",
    "We independently merge all the CFHT Megacam and WIRCAM and some CANDELS in CFHT_Merge notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_merge_dist_plot(\n",
    "    SkyCoord(master_catalogue['ra'], master_catalogue['dec']),\n",
    "    SkyCoord(cfht['cfht_ra'], cfht['cfht_dec'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Given the graph above, we use 0.8 arc-second radius\n",
    "master_catalogue = merge_catalogues(master_catalogue, \n",
    "                                    cfht, \n",
    "                                    \"cfht_ra\", \n",
    "                                    \"cfht_dec\", \n",
    "                                    radius=0.8*u.arcsec)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add HSC-PSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_merge_dist_plot(\n",
    "    SkyCoord(master_catalogue['ra'], master_catalogue['dec']),\n",
    "    SkyCoord(hsc['hsc_ra'], hsc['hsc_dec'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Given the graph above, we use 0.8 arc-second radius\n",
    "master_catalogue = merge_catalogues(master_catalogue, hsc, \"hsc_ra\", \"hsc_dec\", radius=0.8*u.arcsec)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add DECam (DES and DECaLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_merge_dist_plot(\n",
    "    SkyCoord(master_catalogue['ra'], master_catalogue['dec']),\n",
    "    SkyCoord(decam['decam_ra'], decam['decam_dec'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Given the graph above, we use 0.8 arc-second radius\n",
    "master_catalogue = merge_catalogues(master_catalogue, decam, \"decam_ra\", \"decam_dec\", radius=0.8*u.arcsec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Â Add SXDS\n",
    "\n",
    "This now happens in CFHT merging notebook because CANDELS contains Suprime fluxes which need merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# nb_merge_dist_plot(\n",
    "#     SkyCoord(master_catalogue['ra'], master_catalogue['dec']),\n",
    "#     SkyCoord(sxds['sxds_ra'], sxds['sxds_dec'])\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is strange that this does not peak at zero. This is bservable in the original band cross match. It implies there is a persistent offset. Perhaps each band should be astrometrically corrected before the original merge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sxds['flag_merged'].name = 'flag_merged_sxds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Given the graph above, we use 0.8 arc-second radius\n",
    "# master_catalogue = merge_catalogues(master_catalogue, sxds, \"sxds_ra\", \"sxds_dec\", radius=1.0*u.arcsec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add UKIDSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_merge_dist_plot(\n",
    "    SkyCoord(master_catalogue['ra'], master_catalogue['dec']),\n",
    "    SkyCoord(ukidss['ukidss_ra'], ukidss['ukidss_dec'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Given the graph above, we use 0.8 arc-second radius\n",
    "master_catalogue = merge_catalogues(master_catalogue, ukidss, \"ukidss_ra\", \"ukidss_dec\", radius=0.8*u.arcsec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add VIRCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_merge_dist_plot(\n",
    "    SkyCoord(master_catalogue['ra'], master_catalogue['dec']),\n",
    "    SkyCoord(vircam['vircam_ra'], vircam['vircam_dec'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Given the graph above, we use 0.8 arc-second radius\n",
    "master_catalogue = merge_catalogues(master_catalogue, vircam, \"vircam_ra\", \"vircam_dec\", radius=0.8*u.arcsec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add IRAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_merge_dist_plot(\n",
    "    SkyCoord(master_catalogue['ra'], master_catalogue['dec']),\n",
    "    SkyCoord(irac['irac_ra'], irac['irac_dec'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Given the graph above, we use 1 arc-second radius\n",
    "master_catalogue = merge_catalogues(master_catalogue, irac, \"irac_ra\", \"irac_dec\", radius=1.*u.arcsec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning\n",
    "\n",
    "When we merge the catalogues, astropy masks the non-existent values (e.g. when a row comes only from a catalogue and has no counterparts in the other, the columns from the latest are masked for that row). We indicate to use NaN for masked values for floats columns, False for flag columns and -1 for ID columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in master_catalogue.colnames:\n",
    "    #print(col)\n",
    "    if (col.startswith(\"m_\") or col.startswith(\"merr_\") or col.startswith(\"f_\") or col.startswith(\"ferr_\")):\n",
    "        master_catalogue[col] = master_catalogue[col].astype(float)\n",
    "        master_catalogue[col].fill_value = np.nan\n",
    "    elif \"flag\" in col:\n",
    "        master_catalogue[col].fill_value = 0\n",
    "    elif \"id\" in col:\n",
    "        master_catalogue[col].fill_value = -1\n",
    "        \n",
    "master_catalogue = master_catalogue.filled()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "master_catalogue[:10].show_in_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III - Merging flags and stellarity\n",
    "\n",
    "This all happens at the end now after the catalogue has been cut into strips."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV - Adding E(B-V) column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "master_catalogue.add_column(\n",
    "    ebv(master_catalogue['ra'], master_catalogue['dec'])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V - Adding HELP unique identifiers and field columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "master_catalogue.add_column(Column(gen_help_id(master_catalogue['ra'], master_catalogue['dec']),\n",
    "                                   name=\"help_id\"))\n",
    "master_catalogue.add_column(Column(np.full(len(master_catalogue), \"XMM-LSS\", dtype='<U18'),\n",
    "                                   name=\"field\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check that the HELP Ids are unique\n",
    "if len(master_catalogue) != len(np.unique(master_catalogue['help_id'])):\n",
    "    print(\"The HELP IDs are not unique!!!\")\n",
    "else:\n",
    "    print(\"OK!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VI - Cross-matching with spec-z catalogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "specz =  Table.read(\"../../dmu23/dmu23_XMM-LSS/data/XMM-LSS-specz-v2.8.fits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_merge_dist_plot(\n",
    "    SkyCoord(master_catalogue['ra'], master_catalogue['dec']),\n",
    "    SkyCoord(specz['ra'] * u.deg, specz['dec'] * u.deg)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "master_catalogue = specz_merge(master_catalogue, specz, radius=1. * u.arcsec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VIII.a Wavelength domain coverage\n",
    "\n",
    "We add a binary `flag_optnir_obs` indicating that a source was observed in a given wavelength domain:\n",
    "\n",
    "- 1 for observation in optical;\n",
    "- 2 for observation in near-infrared;\n",
    "- 4 for observation in mid-infrared (IRAC).\n",
    "\n",
    "It's an integer binary flag, so a source observed both in optical and near-infrared by not in mid-infrared would have this flag at 1 + 2 = 3.\n",
    "\n",
    "*Note 1: The observation flag is based on the creation of multi-order coverage maps from the catalogues, this may not be accurate, especially on the edges of the coverage.*\n",
    "\n",
    "*Note 2: Being on the observation coverage does not mean having fluxes in that wavelength domain. For sources observed in one domain but having no flux in it, one must take into consideration the different depths in the catalogue we are using.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#candels_moc =   MOC(filename=\"../../dmu0/dmu0_CANDELS-3D-HST/data/CANDELS-3D-HST_XMM-LSS_MOC.fits\") # 1.1\n",
    "candels_moc = MOC(filename=\"../../dmu0/dmu0_CANDELS-UDS/data/hlsp_candels_hst_wfc3_uds-tot-multiband_f160w_v1_MOC.fits\") # 1.2\n",
    "cfht_wirds_moc =  MOC(filename=\"../../dmu0/dmu0_CFHT-WIRDS/data/XMM-LSS_Ks-priors_MOC.fits\")        # 1.3\n",
    "cfhtls_wide_moc = MOC(filename=\"../../dmu0/dmu0_CFHTLS/data/CFHTLS-WIDE_XMM-LSS_MOC.fits\")          # 1.4a\n",
    "cfhtls_deep_moc = MOC(filename=\"../../dmu0/dmu0_CFHTLS/data/CFHTLS-DEEP_XMM-LSS_MOC.fits\")          # 1.4b\n",
    "cfhtls_moc = cfhtls_wide_moc + cfhtls_deep_moc\n",
    "#cfhtlens_moc = MOC(filename=\"../../dmu0/dmu0_CFHTLenS/data/CFHTLenS_XMM-LSS_MOC.fits\")              # 1.5\n",
    "decals_moc =  MOC(filename=\"../../dmu0/dmu0_DECaLS/data/DECaLS_XMM-LSS_MOC.fits\")                   # 1.6\n",
    "des_moc =  MOC(filename=\"../../dmu0/dmu0_DES/data/DES-DR1_XMM-LSS_MOC.fits\")                   # 1.6\n",
    "decam_moc = decals_moc + des_moc\n",
    "servs_moc = MOC(filename=\"../../dmu0/dmu0_DataFusion-Spitzer/data/DF-SERVS_XMM-LSS_MOC.fits\")       # 1.8\n",
    "swire_moc = MOC(filename=\"../../dmu0/dmu0_DataFusion-Spitzer/data/DF-SWIRE_XMM-LSS_MOC.fits\")       # 1.7\n",
    "hsc_wide_moc = MOC(filename=\"../../dmu0/dmu0_HSC/data/HSC-PDR1_wide_XMM-LSS_MOC.fits\")              # 1.9a\n",
    "hsc_deep_moc = MOC(filename=\"../../dmu0/dmu0_HSC/data/HSC-PDR1_deep_XMM-LSS_MOC.fits\")              # 1.9b\n",
    "hsc_udeep_moc = MOC(filename=\"../../dmu0/dmu0_HSC/data/HSC-PDR1_uDeep_XMM-LSS_MOC.fits\")            # 1.9c\n",
    "hsc_moc = hsc_wide_moc + hsc_deep_moc + hsc_udeep_moc\n",
    "ps1_moc = MOC(filename=\"../../dmu0/dmu0_PanSTARRS1-3SS/data/PanSTARRS1-3SS_XMM-LSS_MOC.fits\")       # 1.10\n",
    "sxds_moc = MOC(filename=\"../../dmu0/dmu0_SXDS/data/dmu0_SXDS_MOC.fits\")                             # 1.11\n",
    "sparcs_moc = MOC(filename=\"../../dmu0/dmu0_SpARCS/data/SpARCS_HELP_XMM-LSS_MOC.fits\")               # 1.12\n",
    "dxs_moc = MOC(filename=\"../../dmu0/dmu0_UKIDSS-DXS_DR10plus/data/UKIDSS-DR10plus_XMM-LSS_MOC.fits\") # 1.13\n",
    "uds_moc =  MOC(filename=\"../../dmu0/dmu0_UKIDSS-UDS/data/UKIDSS-UDS_XMM-LSS_MOC.fits\")              # 1.14\n",
    "vipers_moc =  MOC(filename=\"../../dmu0/dmu0_VIPERS-MLS/data/VIPERS-MLS_20160502_MOC.fits\")          # 1.15\n",
    "vhs_moc =   MOC(filename=\"../../dmu0/dmu0_VISTA-VHS/data/VHS_XMM-LSS_MOC.fits\")                     # 1.16\n",
    "video_moc =  MOC(filename=\"../../dmu0/dmu0_VISTA-VIDEO-private/data/VIDEO-all_2016-04-14_fullcat_errfix_XMM-LSS_MOC.fits\")         # 1.17\n",
    "viking_moc = MOC(filename=\"../../dmu0/dmu0_VISTA-VIKING/data/VIKING_XMM-LSS_MOC.fits\")              # 1.18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "was_observed_optical = inMoc(\n",
    "    master_catalogue['ra'], master_catalogue['dec'],\n",
    "    (candels_moc + \n",
    "     cfht_wirds_moc + \n",
    "     cfhtls_moc + \n",
    "     #cfhtlens_moc + \n",
    "     sparcs_moc + \n",
    "     decam_moc + \n",
    "     hsc_moc + \n",
    "     ps1_moc) )\n",
    "\n",
    "was_observed_nir = inMoc(\n",
    "    master_catalogue['ra'], master_catalogue['dec'],\n",
    "    dxs_moc + uds_moc + vhs_moc + video_moc + viking_moc\n",
    ")\n",
    "\n",
    "was_observed_mir = inMoc(\n",
    "    master_catalogue['ra'], master_catalogue['dec'],\n",
    "    servs_moc + swire_moc\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "master_catalogue.add_column(\n",
    "    Column(\n",
    "        1 * was_observed_optical + 2 * was_observed_nir + 4 * was_observed_mir,\n",
    "        name=\"flag_optnir_obs\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VIII.b Wavelength domain detection\n",
    "\n",
    "We add a binary `flag_optnir_det` indicating that a source was detected in a given wavelength domain:\n",
    "\n",
    "- 1 for detection in optical;\n",
    "- 2 for detection in near-infrared;\n",
    "- 4 for detection in mid-infrared (IRAC).\n",
    "\n",
    "It's an integer binary flag, so a source detected both in optical and near-infrared by not in mid-infrared would have this flag at 1 + 2 = 3.\n",
    "\n",
    "*Note 1: We use the total flux columns to know if the source has flux, in some catalogues, we may have aperture flux and no total flux.*\n",
    "\n",
    "To get rid of artefacts (chip edges, star flares, etc.) we consider that a source is detected in one wavelength domain when it has a flux value in **at least two bands**. That means that good sources will be excluded from this flag when they are on the coverage of only one band."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SpARCS is a catalogue of sources detected in r (with fluxes measured at \n",
    "# this prior position in the other bands).  Thus, we are only using the r\n",
    "# CFHT band.\n",
    "# Check to use catalogue flags from HSC and PanSTARRS.\n",
    "#nb_optical_flux = np.zeros(len(master_catalogue), dtype=float)\n",
    "\n",
    "#nb_nir_flux = np.zeros(len(master_catalogue), dtype=float)\n",
    "\n",
    "#nb_mir_flux = np.zeros(len(master_catalogue), dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#has_optical_flux = nb_optical_flux >= 2\n",
    "#has_nir_flux = nb_nir_flux >= 2\n",
    "#has_mir_flux = nb_mir_flux >= 2\n",
    "\n",
    "#master_catalogue.add_column(\n",
    "#    Column(\n",
    "#        1 * has_optical_flux + 2 * has_nir_flux + 4 * has_mir_flux,\n",
    "#        name=\"flag_optnir_det\")\n",
    "#)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IX - Cross-identification table\n",
    "\n",
    "We are producing a table associating to each HELP identifier, the identifiers of the sources in the pristine catalogues. This can be used to easily get additional information from them.\n",
    "\n",
    "For convenience, we also cross-match the master list with the SDSS catalogue and add the objID associated with each source, if any. **TODO: should we correct the astrometry with respect to Gaia positions?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Addind SDSS ids\n",
    "#\n",
    "sdss = Table.read(\"../../dmu0/dmu0_SDSS-DR13/data/SDSS-DR13_XMM-LSS.fits\")['objID', 'ra', 'dec']\n",
    "sdss_coords = SkyCoord(sdss['ra'] * u.deg, sdss['dec'] * u.deg)\n",
    "idx_ml, d2d, _ = sdss_coords.match_to_catalog_sky(SkyCoord(master_catalogue['ra'], master_catalogue['dec']))\n",
    "idx_sdss = np.arange(len(sdss))\n",
    "\n",
    "# Limit the cross-match to 1 arcsec\n",
    "mask = d2d <= 1. * u.arcsec\n",
    "idx_ml = idx_ml[mask]\n",
    "idx_sdss = idx_sdss[mask]\n",
    "d2d = d2d[mask]\n",
    "nb_orig_matches = len(idx_ml)\n",
    "\n",
    "# In case of multiple associations of one master list object to an SDSS object, we keep only the\n",
    "# association to the nearest one.\n",
    "sort_idx = np.argsort(d2d)\n",
    "idx_ml = idx_ml[sort_idx]\n",
    "idx_sdss = idx_sdss[sort_idx]\n",
    "_, unique_idx = np.unique(idx_ml, return_index=True)\n",
    "idx_ml = idx_ml[unique_idx]\n",
    "idx_sdss = idx_sdss[unique_idx]\n",
    "print(\"{} master list rows had multiple associations.\".format(nb_orig_matches - len(idx_ml)))\n",
    "\n",
    "# Adding the ObjID to the master list\n",
    "master_catalogue.add_column(Column(data=np.full(len(master_catalogue), -1, dtype='>i8'), name=\"sdss_id\"))\n",
    "master_catalogue['sdss_id'][idx_ml] = sdss['objID'][idx_sdss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "id_names = []\n",
    "for col in master_catalogue.colnames:\n",
    "    if '_id' in col:\n",
    "        id_names += [col]\n",
    "    if '_intid' in col:\n",
    "        id_names += [col]\n",
    "        \n",
    "print(id_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "master_catalogue[id_names].write(\n",
    "    \"{}/master_list_cross_ident_xmm-lss{}.fits\".format(OUT_DIR, SUFFIX), overwrite=True)\n",
    "id_names.remove('help_id')\n",
    "#master_catalogue.remove_columns(id_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X - Adding HEALPix index\n",
    "\n",
    "We are adding a column with a HEALPix index at order 13 associated with each source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "master_catalogue.add_column(Column(\n",
    "    data=coords_to_hpidx(master_catalogue['ra'], master_catalogue['dec'], order=13),\n",
    "    name=\"hp_idx\"\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XI - Saving the catalogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = [\"help_id\", \"field\", \"ra\", \"dec\", \"hp_idx\"]\n",
    "\n",
    "bands = [column[5:] for column in master_catalogue.colnames if 'f_ap' in column]\n",
    "for band in bands:\n",
    "    columns += [\"f_ap_{}\".format(band), \"ferr_ap_{}\".format(band),\n",
    "                \"m_ap_{}\".format(band), \"merr_ap_{}\".format(band),\n",
    "                \"f_{}\".format(band), \"ferr_{}\".format(band),\n",
    "                \"m_{}\".format(band), \"merr_{}\".format(band),\n",
    "                \"flag_{}\".format(band)]    \n",
    "    \n",
    "columns += [\"stellarity\", \"stellarity_origin\", \"flag_cleaned\", \"flag_merged\", \"flag_gaia\", \"flag_optnir_obs\", \"flag_optnir_det\", \n",
    "            \"zspec\", \"zspec_qual\", \"zspec_association_flag\", \"ebv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We check for columns in the master catalogue that we will not save to disk.\n",
    "print(\"Missing columns: {}\".format(set(master_catalogue.colnames) - set(columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#master_catalogue[columns].write(\"{}/master_catalogue_xmm-lss_low-memory{}.fits\".format(OUT_DIR, SUFFIX), overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XII - folding in the photometry\n",
    "On XMM-LSS there is too much data to load all in to memory at once so we perform the cross matching without photometry columns. Only now do we fold in the photometry data by first cutting the catalogue up in to manageable sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "split_length = 100000 #number of sources to include in every sub catalogue\n",
    "num_files = int(np.ceil(len(master_catalogue)/split_length))\n",
    "print(num_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Sort catalogue by HELP id so that it is split up in RA strips\n",
    "master_catalogue.sort('help_id')\n",
    "#Remove all the old ids as they interfere with join\n",
    "old_id_names = [\n",
    " 'candels_id',\n",
    " 'cfhtls-wide_id',\n",
    " 'cfhtls-deep_id',\n",
    " 'sparcs_intid',\n",
    " 'wirds_id',\n",
    " 'vipers_id',\n",
    " 'sxds_intid',\n",
    " 'sxds_b_id',\n",
    " 'sxds_v_id',\n",
    " 'sxds_r_id',\n",
    " 'sxds_i_id',\n",
    " 'sxds_z_id',\n",
    "    \n",
    " 'hsc-wide_id',\n",
    " 'hsc-deep_id',\n",
    " 'hsc-udeep_id',\n",
    "    \n",
    " 'des_id',\n",
    " 'decals_id',\n",
    "\n",
    " 'dxs_id',\n",
    " 'uds_id',\n",
    " \n",
    " 'vhs_id',\n",
    " 'video_id',\n",
    " 'viking_id',\n",
    "\n",
    " 'servs_intid',\n",
    " 'swire_intid']\n",
    "master_catalogue.remove_columns(old_id_names)\n",
    "# The old id names will be added back in by \n",
    "# the join so I leave them in the list here to be \n",
    "# removed before the save of the sub catalogue\n",
    "# id_names.remove(old_id_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#There is candels data on three seperate merged catalogues so duplicates must be removed from two\n",
    "irac_merged = Table.read(\"{}/irac_merged_catalogue_xmm-lss.fits\".format(TMP_DIR))\n",
    "irac_merged.remove_columns(['candels_id',\n",
    "                            'candels_stellarity',\n",
    "                            'candels_flag_cleaned',\n",
    "                            'candels_flag_gaia'])\n",
    "\n",
    "ukidss_merged = Table.read(\"{}/ukidss_merged_catalogue_xmm-lss.fits\".format(TMP_DIR))\n",
    "ukidss_merged.remove_columns(['candels_id',\n",
    "                              'candels_stellarity',\n",
    "                              'candels_flag_cleaned',\n",
    "                              'candels_flag_gaia'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "surveys = [\n",
    "    \n",
    "\n",
    "    #['sxds',         \"SXDS.fits\",           Table.read(\"{}/SXDS.fits\".format(TMP_DIR)),          'sxds_intid'], \n",
    "    #['candels',      \"CANDELS.fits\",        Table.read(\"{}/CANDELS.fits\".format(TMP_DIR)),       'candels_id'],\n",
    "    #['cfhtls_wide',  \"CFHTLS-WIDE.fits\",    Table.read(\"{}/CFHTLS-WIDE.fits\".format(TMP_DIR)),   'cfhtls-wide_id'],\n",
    "    #['cfhtls_deep',  \"CFHTLS-DEEP.fits\",    Table.read(\"{}/CFHTLS-DEEP.fits\".format(TMP_DIR)),   'cfhtls-deep_id'],\n",
    "    #['sparcs',       \"SpARCS.fits\",         Table.read(\"{}/SpARCS.fits\".format(TMP_DIR)),        'sparcs_intid'], \n",
    "    #['cfht_wirds',   \"CFHT-WIRDS.fits\",     Table.read(\"{}/CFHT-WIRDS.fits\".format(TMP_DIR)),    'wirds_intid' ],\n",
    "    #['vipers',       \"VIPERS.fits\",         Table.read(\"{}/VIPERS.fits\".format(TMP_DIR)),        'vipers_id'],\n",
    "    ['cfht',       \n",
    "     \"cfht_merged_catalogue_xmm-lss.fits\",        \n",
    "     Table.read(\"{}/cfht_merged_catalogue_xmm-lss.fits\".format(TMP_DIR)),        \n",
    "     'cfht_intid'], \n",
    "    \n",
    "    #['decals',       \"DECaLS.fits\",         Table.read(\"{}/DECaLS.fits\".format(TMP_DIR)),        'decals_id'],\n",
    "    ['decam',       \n",
    "     \"decam_merged_catalogue_xmm-lss.fits\",         \n",
    "     Table.read(\"{}/decam_merged_catalogue_xmm-lss.fits\".format(TMP_DIR)),        \n",
    "     'decam_intid'],\n",
    "    \n",
    "    #['servs',        \"SERVS.fits\",          Table.read(\"{}/SERVS.fits\".format(TMP_DIR)),         'servs_intid'],\n",
    "    #['swire',        \"SWIRE.fits\",          Table.read(\"{}/SWIRE.fits\".format(TMP_DIR)),         'swire_intid'],  \n",
    "    ['irac',       \n",
    "     \"irac_merged_catalogue_xmm-lss.fits\",\n",
    "     irac_merged,        \n",
    "     'irac_intid'], \n",
    "    \n",
    "    #['hsc_wide ',    \"HSC-WIDE.fits\",       Table.read(\"{}/HSC-WIDE.fits\".format(TMP_DIR)),      'hsc-wide_id' ],\n",
    "    #['hsc_deep',     \"HSC-DEEP.fits\",       Table.read(\"{}/HSC-DEEP.fits\".format(TMP_DIR)),      'hsc-deep_id'],\n",
    "    #['hsc_udeep',    \"HSC-UDEEP.fits\",      Table.read(\"{}/HSC-UDEEP.fits\".format(TMP_DIR)),     'hsc-udeep_id'],  \n",
    "    ['hsc',       \n",
    "     \"hsc_merged_catalogue_xmm-lss.fits\",        \n",
    "     Table.read(\"{}/hsc_merged_catalogue_xmm-lss.fits\".format(TMP_DIR)),        \n",
    "     'hsc_intid'], \n",
    "    \n",
    "    ['ps1',          \"PS1.fits\",            Table.read(\"{}/PS1.fits\".format(TMP_DIR)),           'ps1_id'],    \n",
    "    \n",
    "                  \n",
    "    \n",
    "    #['dxs',          \"UKIDSS-DXS.fits\",     Table.read(\"{}/UKIDSS-DXS.fits\".format(TMP_DIR)),    'dxs_id'],          \n",
    "    #['uds',          \"UKIDSS-UDS.fits\",     Table.read(\"{}/UKIDSS-UDS.fits\".format(TMP_DIR)),    'uds_id'],    \n",
    "    ['ukidss',       \n",
    "     \"ukidss_merged_catalogue_xmm-lss.fits\",        \n",
    "     ukidss_merged,         \n",
    "     'ukidss_intid'], \n",
    "    \n",
    "   \n",
    "    \n",
    "    #['vhs',          \"VISTA-VHS.fits\",      Table.read(\"{}/VISTA-VHS.fits\".format(TMP_DIR)),     'vhs_id'],           \n",
    "    #['video',        \"VISTA-VIDEO.fits\",    Table.read(\"{}/VISTA-VIDEO.fits\".format(TMP_DIR)),   'video_id'],       \n",
    "    #['viking',       \"VISTA-VIKING.fits\",   Table.read(\"{}/VISTA-VIKING.fits\".format(TMP_DIR)), 'viking_id']  \n",
    "    ['vircam',       \n",
    "     \"vista_merged_catalogue_xmm-lss.fits\",        \n",
    "     Table.read(\"{}/vista_merged_catalogue_xmm-lss.fits\".format(TMP_DIR)),        \n",
    "     'vircam_intid']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n=0\n",
    "for sub_file in range(num_files):\n",
    "    \n",
    "    sub_catalogue = master_catalogue[n*split_length:(n+1)*split_length]\n",
    "    #print(n)\n",
    "    for survey in surveys:\n",
    "        #print(survey[0])\n",
    "        sub_catalogue = join(sub_catalogue, \n",
    "                               survey[2], #Table.read(\"{}/{}\".format(TMP_DIR, survey[1])),\n",
    "                               join_type='left',\n",
    "                               metadata_conflicts='silent',\n",
    "                               keys=survey[3]\n",
    "                            )\n",
    "        \n",
    "        \n",
    "        \n",
    "    #Each pristine catalogue contains a flag indicating if the source was associated to a another nearby source that was removed during the cleaning process. We merge these flags in a single one.\n",
    "\n",
    "\n",
    "    flag_cleaned_columns = [column for column in sub_catalogue.colnames\n",
    "                            if 'flag_cleaned' in column]\n",
    "\n",
    "    flag_column = np.zeros(len(sub_catalogue), dtype=bool)\n",
    "    for column in flag_cleaned_columns:\n",
    "        flag_column |= sub_catalogue[column]\n",
    "    \n",
    "    sub_catalogue.add_column(Column(data=flag_column, name=\"flag_cleaned\"))\n",
    "    sub_catalogue.remove_columns(flag_cleaned_columns)\n",
    "    #combining the flag_merged column which contains information regarding multiple associations\n",
    "    \n",
    "    \n",
    "    sub_catalogue['flag_merged'].name = 'flag_merged_tmp'\n",
    "    flag_merged_columns = [column for column in sub_catalogue.colnames\n",
    "                            if 'flag_merged' in column]\n",
    "    \n",
    "    flag_merged_column = np.zeros(len(sub_catalogue), dtype=bool)\n",
    "    for column in flag_merged_columns:\n",
    "        flag_merged_column |= sub_catalogue[column]\n",
    "    \n",
    "    sub_catalogue.add_column(Column(data=flag_merged_column, name=\"flag_merged\"))\n",
    "    sub_catalogue.remove_columns(flag_merged_columns)\n",
    "    sub_catalogue['flag_merged'].name = 'flag_merged_tmp'\n",
    "    flag_merged_columns = [column for column in sub_catalogue.colnames\n",
    "                            if 'flag_merged' in column]\n",
    "    \n",
    "    flag_merged_column = np.zeros(len(sub_catalogue), dtype=bool)\n",
    "    for column in flag_merged_columns:\n",
    "        flag_merged_column |= sub_catalogue[column]\n",
    "    \n",
    "    sub_catalogue.add_column(Column(data=flag_merged_column, name=\"flag_merged\"))\n",
    "    sub_catalogue.remove_columns(flag_merged_columns)\n",
    "    #Each pristine catalogue contains a flag indicating the probability of a source being a Gaia object (0: not a Gaia object, 1: possibly, 2: probably, 3: definitely). We merge these flags taking the highest value.\n",
    "\n",
    "\n",
    "    flag_gaia_columns = [column for column in sub_catalogue.colnames\n",
    "                         if 'flag_gaia' in column]\n",
    "\n",
    "    sub_catalogue.add_column(Column(\n",
    "        data=np.max([sub_catalogue[column] for column in flag_gaia_columns], axis=0),\n",
    "        name=\"flag_gaia\"\n",
    "    ))\n",
    "    sub_catalogue.remove_columns(flag_gaia_columns)\n",
    "    #Each prisitine catalogue may contain one or several stellarity columns indicating the #probability (0 to 1) of each source being a star. We merge these columns taking the highest value. We keep trace of the origin of the stellarity.\n",
    "\n",
    "\n",
    "\n",
    "    stellarity_columns = [column for column in sub_catalogue.colnames\n",
    "                          if 'stellarity' in column]\n",
    "\n",
    "    #print(\", \".join(stellarity_columns))\n",
    "\n",
    "\n",
    "\n",
    "    # We create an masked array with all the stellarities and get the maximum value, as well as its\n",
    "    # origin.  Some sources may not have an associated stellarity.\n",
    "    stellarity_array = np.array([sub_catalogue[column] for column in stellarity_columns])\n",
    "    stellarity_array = np.ma.masked_array(stellarity_array, np.isnan(stellarity_array))\n",
    "\n",
    "    max_stellarity = np.max(stellarity_array, axis=0)\n",
    "    max_stellarity.fill_value = np.nan\n",
    "\n",
    "    no_stellarity_mask = max_stellarity.mask\n",
    "\n",
    "    sub_catalogue.add_column(Column(data=max_stellarity.filled(), name=\"stellarity\"))\n",
    "\n",
    "    stellarity_origin = np.full(len(sub_catalogue), \"NO_INFORMATION\", dtype=\"S20\")\n",
    "    stellarity_origin[~no_stellarity_mask] = np.array(stellarity_columns)[np.argmax(stellarity_array, axis=0)[~no_stellarity_mask]]\n",
    "\n",
    "    sub_catalogue.add_column(Column(data=stellarity_origin, name=\"stellarity_origin\"))\n",
    "\n",
    "    sub_catalogue.remove_columns(stellarity_columns)\n",
    "\n",
    "    for col in sub_catalogue.colnames:\n",
    "        #print(col)\n",
    "        if (col.startswith(\"m_\") or col.startswith(\"merr_\") or col.startswith(\"f_\") or col.startswith(\"ferr_\")):\n",
    "            sub_catalogue[col] = sub_catalogue[col].astype(float)\n",
    "            sub_catalogue[col].fill_value = np.nan\n",
    "        elif \"flag\" in col:\n",
    "            sub_catalogue[col].fill_value = 0\n",
    "        elif \"id\" in col:\n",
    "            sub_catalogue[col].fill_value = -1\n",
    "        \n",
    "    sub_catalogue = sub_catalogue.filled()\n",
    "        \n",
    "        \n",
    "    nb_optical_flux = (\n",
    "        # CANDELS\n",
    "        1 * ~np.isnan(sub_catalogue['f_acs_f606w']) + \n",
    "        1 * ~np.isnan(sub_catalogue['f_acs_f814w']) +\n",
    "        1 * ~np.isnan(sub_catalogue['f_wfc3_f125w']) +\n",
    "        1 * ~np.isnan(sub_catalogue['f_wfc3_f160w']) +\n",
    "\n",
    "        # DES and DECaLS\n",
    "        1 * ~np.isnan(sub_catalogue['f_decam_g']) + \n",
    "        1 * ~np.isnan(sub_catalogue['f_decam_r']) +\n",
    "        1 * ~np.isnan(sub_catalogue['f_decam_i']) +\n",
    "        1 * ~np.isnan(sub_catalogue['f_decam_z']) +\n",
    "        1 * ~np.isnan(sub_catalogue['f_decam_y']) +\n",
    "        # HSC\n",
    "        1 * ~np.isnan(sub_catalogue['f_suprime_g']) + \n",
    "        1 * ~np.isnan(sub_catalogue['f_suprime_r']) +\n",
    "        1 * ~np.isnan(sub_catalogue['f_suprime_i']) +\n",
    "        1 * ~np.isnan(sub_catalogue['f_suprime_z']) +\n",
    "        1 * ~np.isnan(sub_catalogue['f_suprime_y']) +\n",
    "        1 * ~np.isnan(sub_catalogue['f_suprime_n921']) +\n",
    "        1 * ~np.isnan(sub_catalogue['f_suprime_n816']) +\n",
    "        # PanSTARRS\n",
    "        1 * ~np.isnan(sub_catalogue['f_gpc1_g']) +\n",
    "        1 * ~np.isnan(sub_catalogue['f_gpc1_r']) +\n",
    "        1 * ~np.isnan(sub_catalogue['f_gpc1_i']) +\n",
    "        1 * ~np.isnan(sub_catalogue['f_gpc1_z']) +\n",
    "        1 * ~np.isnan(sub_catalogue['f_gpc1_y']) +\n",
    "        # CFHT\n",
    "        1 * ~np.isnan(sub_catalogue['f_megacam_u']) +\n",
    "        1 * ~np.isnan(sub_catalogue['f_megacam_g']) +\n",
    "        1 * ~np.isnan(sub_catalogue['f_megacam_r']) +\n",
    "        1 * ~np.isnan(sub_catalogue['f_megacam_z']) +\n",
    "        1 * ~np.isnan(sub_catalogue['f_megacam_y']) \n",
    "    )\n",
    "\n",
    "    nb_nir_flux = (\n",
    "        # CFHT-WIRCAM\n",
    "        1 * ~np.isnan(sub_catalogue['f_wircam_j']) +\n",
    "        1 * ~np.isnan(sub_catalogue['f_wircam_h']) +\n",
    "        1 * ~np.isnan(sub_catalogue['f_wircam_ks']) +\n",
    "        # UKIDSS\n",
    "        1 * ~np.isnan(sub_catalogue['f_ukidss_j']) +\n",
    "        1 * ~np.isnan(sub_catalogue['f_ukidss_h']) +\n",
    "        1 * ~np.isnan(sub_catalogue['f_ukidss_k']) +\n",
    "        # VISTA\n",
    "        1 * ~np.isnan(sub_catalogue['f_vista_z']) +\n",
    "        1 * ~np.isnan(sub_catalogue['f_vista_y']) +\n",
    "        1 * ~np.isnan(sub_catalogue['f_vista_j']) +\n",
    "        1 * ~np.isnan(sub_catalogue['f_vista_h']) +\n",
    "        1 * ~np.isnan(sub_catalogue['f_vista_ks'])\n",
    "    )\n",
    "\n",
    "    nb_mir_flux = (\n",
    "        1 * ~np.isnan(sub_catalogue['f_irac_i1']) +\n",
    "        1 * ~np.isnan(sub_catalogue['f_irac_i2']) +\n",
    "        1 * ~np.isnan(sub_catalogue['f_irac_i3']) +\n",
    "        1 * ~np.isnan(sub_catalogue['f_irac_i4']) \n",
    "    )\n",
    "        \n",
    "    has_optical_flux = nb_optical_flux >= 2\n",
    "    has_nir_flux = nb_nir_flux >= 2\n",
    "    has_mir_flux = nb_mir_flux >= 2\n",
    "\n",
    "    sub_catalogue.add_column(\n",
    "        Column(\n",
    "            1 * has_optical_flux + 2 * has_nir_flux + 4 * has_mir_flux,\n",
    "            name=\"flag_optnir_det\")\n",
    "    )\n",
    "        \n",
    "    #print('Finished join')\n",
    "    sub_catalogue.remove_columns(id_names)\n",
    "    #sub_catalogue.remove_columns(['sxds_b_id', 'sxds_v_id', 'sxds_r_id', 'sxds_i_id', 'sxds_z_id'])\n",
    "    \n",
    "    for col in sub_catalogue.colnames:\n",
    "        if col.endswith('_ra'):\n",
    "            sub_catalogue.remove_column(col)\n",
    "        if col.endswith('_dec'):\n",
    "            sub_catalogue.remove_column(col)\n",
    "        if '_vircam_' in col:\n",
    "            sub_catalogue.rename_column(col, col.replace('_vircam_', '_vista_'))\n",
    "            \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    sub_catalogue.write(\"{}/tiles/sub_catalogue_xmm-lss{}_{}.fits\".format(OUT_DIR, SUFFIX, n), overwrite=True)\n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to generate final catalogue\n",
    "After this notebook has been run there will be a set of sub catalogues in data/tiles/\n",
    "\n",
    "These need to be stacked using stilts:\n",
    "\n",
    "<pre>\n",
    "suffix=20180111\n",
    "\n",
    "ls ./data/tiles/sub_catalogue_xmm-lss_$suffix_*.fits > ./data/tiles/fits_list_$suffix.lis\n",
    "\n",
    "stilts tcat in=@./data/tiles/fits_list_$suffix.lis out=./data/master_catalogue_xmm-lss_$suffix.fits\n",
    "</pre>\n",
    "\n",
    "For many purposes this file may be too large. In order to run checks and diagnostics we typically take a subset using something like:\n",
    "\n",
    "<pre>\n",
    "stilts tpipe cmd='every 10' ./data/master_catalogue_xmm-lss_$suffix.fits omode=out out=./data/master_catalogue_xmm-lss_RANDOM10PCSAMPLE_$suffix.fits\n",
    "</pre>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (herschelhelp_internal)",
   "language": "python",
   "name": "helpint"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
