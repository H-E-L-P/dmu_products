{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab\n",
    "import pymoc\n",
    "import xidplus\n",
    "\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from astropy.table import Table\n",
    "import os\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook uses all the raw data from the Blind SPIRE catalogue to create XID+ prior object and relevant tiling scheme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in XID+SPIRE catalogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = 'dmu_products/dmu22/'\n",
    "name_field= ['AKARI-SEP_SPIRE','EGS_SPIRE','ELAIS-S1_SPIRE','SA13_SPIRE','XMM-13hr_SPIRE',\\\n",
    "            'COSMOS_SPIRE','ELAIS-N2_SPIRE','HDF-N_SPIRE','SPIRE-NEP_SPIRE','xFLS_SPIRE','ELAIS-N1_SPIRE',\\\n",
    "            'XMM-LSS_SPIRE','Lockman-SWIRE_SPIRE','CDFS-SWIRE_SPIRE', 'GAMA-09_SPIRE','GAMA-12_SPIRE',\\\n",
    "            'GAMA-15_SPIRE','SSDF_SPIRE','Bootes_SPIRE','HATLAS-NGP_SPIRE','HATLAS-SGP_SPIRE']\n",
    "which_field = 19\n",
    "name_field = name_field[which_field] # select a field, in this case SA13\n",
    "print(name_field)\n",
    "XID_table=Table.read(loc+name_field+'_all.fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XID_table[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The uncertianties become Gaussian by $\\sim 20 \\mathrm{\\mu Jy}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loc = 'dmu19/dmu19_HELP-SPIRE-maps'\n",
    "name = [name_field+'250_v1.0.fits',name_field+'350_v1.0.fits',name_field+'500_v1.0.fits']\n",
    "pswfits=loc+name[0]\n",
    "pmwfits=loc+name[1]\n",
    "plwfits=loc+name[2]\n",
    "os.mkdir('./OUT_'+name_field[0:-6])\n",
    "output_folder ='./OUT_'+name_field[0:-6]+'/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "from astropy import wcs\n",
    "\n",
    "#-----250-------------\n",
    "hdulist = fits.open(pswfits)\n",
    "im250phdu=hdulist[0].header\n",
    "im250hdu=hdulist[1].header\n",
    "\n",
    "im250=hdulist['IMAGE'].data*1.0E3 #convert to mJy\n",
    "nim250=hdulist['ERROR'].data*1.0E3 #convert to mJy\n",
    "w_250 = wcs.WCS(hdulist[1].header)\n",
    "pixsize250 = hdulist[\"Matchedfilter\"].header[\"PIXSIZE\"] \n",
    "\n",
    "hdulist.close()\n",
    "#-----350-------------\n",
    "hdulist = fits.open(pmwfits)\n",
    "im350phdu=hdulist[0].header\n",
    "im350hdu=hdulist[1].header\n",
    "\n",
    "im350=hdulist['IMAGE'].data*1.0E3 #convert to mJy\n",
    "nim350=hdulist['ERROR'].data*1.0E3 #convert to mJy\n",
    "w_350 = wcs.WCS(hdulist[1].header)\n",
    "pixsize350 = hdulist[\"Matchedfilter\"].header[\"PIXSIZE\"] \n",
    "hdulist.close()\n",
    "#-----500-------------\n",
    "hdulist = fits.open(plwfits)\n",
    "im500phdu=hdulist[0].header\n",
    "im500hdu=hdulist[1].header\n",
    "im500=hdulist['IMAGE'].data*1.0E3 #convert to mJy\n",
    "nim500=hdulist['ERROR'].data*1.0E3 #convert to mJy\n",
    "w_500 = wcs.WCS(hdulist[1].header)\n",
    "pixsize500 = hdulist[\"Matchedfilter\"].header[\"PIXSIZE\"] \n",
    "\n",
    "hdulist.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set XID+ prior class\n",
    "ID = np.arange(1,np.size(XID_table['RA'])+1)\n",
    "ID = ID.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#---prior250--------\n",
    "prior250=xidplus.prior(im250,nim250,im250phdu,im250hdu)#Initialise with map, uncertianty map, wcs info and primary header\n",
    "prior250.prior_cat(XID_table['RA'],XID_table['DEC'],name_field+'_250_XID.fits',ID=ID)#Set input catalogue\n",
    "prior250.prior_bkg(-5.0,5)#Set prior on background (assumes Gaussian pdf with mu and sigma)\n",
    "#---prior350--------\n",
    "prior350=xidplus.prior(im350,nim350,im350phdu,im350hdu)\n",
    "prior350.prior_cat(XID_table['RA'],XID_table['DEC'],name_field+'_350_XID.fits',ID=ID)#Set input catalogue\n",
    "prior350.prior_bkg(-5.0,5)\n",
    "\n",
    "#---prior500--------\n",
    "prior500=xidplus.prior(im500,nim500,im500phdu,im500hdu)\n",
    "prior500.prior_cat(XID_table['RA'],XID_table['DEC'],name_field+'_500_XID.fits',ID=ID)#Set input catalogue\n",
    "prior500.prior_bkg(-5.0,5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pixsize array (size of pixels in arcseconds)\n",
    "pixsize=np.array([pixsize250,pixsize350,pixsize500])\n",
    "#point response function for the three bands\n",
    "prfsize=np.array([18.15,25.15,36.3])\n",
    "#use Gaussian2DKernel to create prf (requires stddev rather than fwhm hence pfwhm/2.355)\n",
    "from astropy.convolution import Gaussian2DKernel\n",
    "\n",
    "##---------fit using Gaussian beam-----------------------\n",
    "prf250=Gaussian2DKernel(prfsize[0]/2.355,x_size=101,y_size=101)\n",
    "prf250.normalize(mode='peak')\n",
    "prf350=Gaussian2DKernel(prfsize[1]/2.355,x_size=101,y_size=101)\n",
    "prf350.normalize(mode='peak')\n",
    "prf500=Gaussian2DKernel(prfsize[2]/2.355,x_size=101,y_size=101)\n",
    "prf500.normalize(mode='peak')\n",
    "\n",
    "pind250=np.arange(0,101,1)*1.0/pixsize[0] #get 250 scale in terms of pixel scale of map\n",
    "pind350=np.arange(0,101,1)*1.0/pixsize[1] #get 350 scale in terms of pixel scale of map\n",
    "pind500=np.arange(0,101,1)*1.0/pixsize[2] #get 500 scale in terms of pixel scale of map\n",
    "\n",
    "prior250.set_prf(prf250.array,pind250,pind250)#requires psf as 2d grid, and x and y bins for grid (in pixel scale)\n",
    "prior350.set_prf(prf350.array,pind350,pind350)\n",
    "prior500.set_prf(prf500.array,pind500,pind500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "#from moc, get healpix pixels at a given order\n",
    "from xidplus import moc_routines\n",
    "\n",
    "order=7 \n",
    "tiles=moc_routines.get_HEALPix_pixels(order,prior250.sra,prior250.sdec,unique=True)\n",
    "order_large=6\n",
    "tiles_large=moc_routines.get_HEALPix_pixels(order_large,prior250.sra,prior250.sdec,unique=True)\n",
    "print('----- There are '+str(len(tiles))+' tiles required for input catalogue and '+str(len(tiles_large))+' large tiles')\n",
    "#output_folder='./'\n",
    "outfile=output_folder+'Master_prior.pkl'\n",
    "\n",
    "with open(outfile, 'wb') as f:\n",
    "    xidplus.io.pickle.dump({'priors':[prior250,prior350,prior500],'tiles':tiles,'order':order,'version':xidplus.io.git_version()},f)\n",
    "    \n",
    "outfile=output_folder+'Tiles.pkl'\n",
    "with open(outfile, 'wb') as f:\n",
    "    pickle.dump({'tiles':tiles,'order':order,'tiles_large':tiles_large,'order_large':order_large,'version':xidplus.io.git_version()},f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## The Master_prior.pkl and Tiles.pkl are used to run XID+\n",
    "# Running on Apollo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "% mv XID\\_plus\\_hier.sh OUT\\_\"name_field\"\n",
    "\n",
    "% cd OUT_\"name_field\"\n",
    "\n",
    "% module load sge\n",
    "\n",
    "% qsub -t 1-$n_hier -q mps.q -jc mps.short XID_plus_hier.sh \n",
    "\n",
    "### n_hier is the number of large tiles\n",
    "\n",
    "% cd ..\n",
    "\n",
    "% qsub -t 1-$n_tiles -pe openmp 4 -l h_rt=6:00:00 -l m_mem_free=13G -q mps.q XID_plus_tile.sh\n",
    "### n_hier is the number of small tiles\n",
    "### Then combine the Bayesian maps into one:\n",
    "\n",
    "% python make_combined_map.py\n",
    "\n",
    "% cd output\n",
    "\n",
    "% ls *cat.fits > cat_files \n",
    "\n",
    "% module load starlink/hikianalia-64bit\n",
    "\n",
    "% stilts tcat ifmt=fits in=@cat_files out=dmu22_XID+SPIRE_\"name_field\"_BLIND.fits\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## The data products are:\n",
    "### dmu22XID+SPIRE\"name_field\"_BLIND.fits\n",
    "#### dmu22_XID+SPIRE\\_psw_\"name_field\"_Bayes_Pval\n",
    "#### dmu22_XID+SPIRE\\_pmw_\"name_field\"_Bayes_Pval\n",
    "#### dmu22_XID+SPIRE\\_plw_\"name_field\"_Bayes_Pval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final validation of the data can be found at: \n",
    "# http://hedam.lam.fr/HELP/data/dmu_products/dmu22/\n",
    "# dmu22_\"name\\_field\"/XID+BLIND_\"name_field\"_final_processing.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
